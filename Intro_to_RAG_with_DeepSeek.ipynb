{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9390037",
   "metadata": {},
   "source": [
    "# RAG-based chatbot using DeepSeek-R1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefa879",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) is a framework that combines traditional information retrieval with generative language models (LLMs). It helps to improve the accuracy and relevance of information provided by LLMs. It is used for building AI applications that generate precise, grounded, and contextually relevant answers by retrieving and synthesizing knowledge from external sources.\n",
    "\n",
    "### How does RAG work? \n",
    "- Retrieval: Search through databases, books, and other sources for information\n",
    "- Augmentation: Extract key facts, ideas, and quotes from the sources\n",
    "- Generation: Use the extracted information to create new, original content\n",
    "- Steps\n",
    "    - 1. Data collection\n",
    "    - 2. Data chunking: Breaking data down into smaller, more manageable pieces.This improves efficiency since the system can quickly obtain the most relevant pieces of information instead of processing entire documents.\n",
    "    - 3. Document embeddings: Document parts need be converted into a vector representation. This involves transforming text data into embeddings, which are numeric representations that capture the semantic meaning behind text. It allows the system to understand user queries and match them with relevant information in the source dataset based on the meaning of the text, instead of a simple word-to-word comparison. This method ensures that the responses are relevant and aligned with the user’s query.\n",
    "    - 4. Handling user queries: Query must be converted into an embedding or vector representation. The same model must be used for both the document and query embedding to ensure uniformity between the two. The system compares the query embedding with the document embeddings. It identifies and retrieves chunks whose embeddings are most similar to the query embedding, using measures such as cosine similarity and Euclidean distance.\n",
    "    - 5. Generating responses with an LLM: The retrieved text chunks, along with the initial user query, are fed into a language model. The algorithm will use this information to generate a coherent response to the user’s questions through a chat interface.\n",
    "\n",
    "\n",
    "### Why is RAG useful?\n",
    "- More accurate: RAG can provide more precise, reliable, and context-specific responses \n",
    "- More relevant: RAG can provide up-to-date information by connecting LLMs to news sites, social media, and other frequently-updated sources \n",
    "- Less need for retraining: RAG can reduce the need to feed and retrain LLMs on new examples \n",
    "\n",
    "### Why Use DeepSeek-R1 With RAG?\n",
    "- Cost and privacy benefits: DeepSeek-R1 can be run locally to avoid API cost and keep sensitive data secure.\n",
    "- Offline capabilities: Retrieval systems can work without internet access once the model is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e88706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f2447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out what different forms of cat communication there are. I know a little bit about birds and their communication, but cats have been on my mind for some time. Let me think through this step by step.\n",
      "\n",
      "First off, I remember that humans use various methods to communicate. It's all about conveying emotions or information in a way that makes sense to the other person. Maybe cats do something similar, but they might have their own unique ways of sharing sounds and sounds with others. \n",
      "\n",
      "I recall that some cats are vocalists. They can emit loud noises from their paws or faces. That seems pretty straightforward. People often use this when they're happy, sad, or excited. It's like a way to express themselves physically. So maybe cats have a similar system where they use their paws or facial expressions to signal their mood.\n",
      "\n",
      "Then there are the sounds that come out of their mouths and snouts. I've seen some cats making clear whistles when they're happy or calm. This might be another form of communication, but it's probably more about vocalization than visual signals. \n",
      "\n",
      "I think some cats can also use vibrations from their ears to communicate. When a cat is stressed or stressed, their ears shake outward. That sounds a lot like a \"noahie\" or \"tuxedo,\" which I know refers to a type of noise made by stress. So maybe that's another form, using sound rather than physical contact.\n",
      "\n",
      "Honeybees are some kind of small cats, right? Or maybe it's more about the names. No, wait, honeybee-like sounds—maybe I'm mixing things up. Perhaps they're referring to how bees or other pollinators communicate. But in any case, I think honeybees and their communication systems have something with their ears too.\n",
      "\n",
      "I also remember that cats can show affection through their paws. Like when someone touches a pet cat, the other cat's paw might sound like it wants to scratch. That sounds more personal and affectionate than just vocalization or noise. It's a direct physical signal for touch and care.\n",
      "\n",
      "There's something about when a cat moves its head. If a cat is happy, it might bob or swivel its head slightly. That's another vocal method, almost like a sign of affection. Cats are often seen on farms with these movements during feeding times, so that makes sense as a form of communication related to socializing.\n",
      "\n",
      "I think some cats can also produce \"dancing\" noises when they’re happy and making friends. The paws might move in a graceful way, as if they’re dancing around, which is both expressive and friendly. That's another vocal method without moving their ears or face too much.\n",
      "\n",
      "When it comes to emotions, like anxiety or fear, I believe cats can make specific noises that trigger stress. These might be different from the vocalizations used by humans, perhaps more subtle or specific to cats. Maybe something like a \"stressed\" whine or a \"feline cough,\" but those aren't very common for cats.\n",
      "\n",
      "So putting this all together, the forms of cat communication include vocalizations (like paws, faces, snout), sound vibrations, honeybees' sounds (if that's applicable), affection through paw movements and bobbing, social dance-like movements, and emotional noises. I'm not entirely sure about some terms like \"honeybee-like sounds,\" but I think it refers to the paws as a method of communication.\n",
      "\n",
      "I should probably list these out more clearly, maybe with examples for each form so I can see them all. That way, when someone asks what cat forms communicate, they can have an organized answer with different categories and specific methods within each.\n",
      "</think>\n",
      "\n",
      "**Cats' Forms of Communication: An Organized Overview**\n",
      "\n",
      "Cats possess a variety of communication mechanisms that go beyond the verbal or non-verbal signals humans use. Here's a structured breakdown:\n",
      "\n",
      "1. **Vocalizations**\n",
      "   - **Paw Sounds**: Cats emit loud noises from their paws, often signaling happiness or calmness.\n",
      "   - **Face Expressions**: Through facial movements and expressions, cats convey mood without sound.\n",
      "\n",
      "2. **Sound Vibrations**\n",
      "   - **Ear Shaking**: When stressed, cats' ears shake outward, mimicking \"noahie\" (stressed noise) or \"tuxedo.\"\n",
      "\n",
      "3. **Honeybee-Like Sounds**\n",
      "   - While specifically referring to bees and their communication methods, this term might imply specific vocalizations relevant to certain species.\n",
      "\n",
      "4. **Affection Through Paws**\n",
      "   - Cats can sound affectionate with paw movements, especially during touch interactions.\n",
      "\n",
      "5. **Social Dance-like Movements**\n",
      "   - Happy cats may bob or swivel their head, showing friendliness and social interaction.\n",
      "\n",
      "6. **Emotional Noise**\n",
      "   - Specific noises triggered by emotions like anxiety or fear, though not universally understood.\n",
      "\n",
      "**Summary:** Cats communicate through vocalizations (paws, faces), sound vibrations, affectional paw movements, social dance-like behaviors, emotional signals, and non-verbal cues. These methods reflect cats' preferences for physical and expressive communication, often used to express care, happiness, and social interaction.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What are the different forms of cat communication?\"},\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f30169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'cat-facts.txt'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.text import TextLoader\n",
    "loader = TextLoader('cat-facts.txt', encoding='utf8')\n",
    "text_file = loader.load()\n",
    "text_file[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd0b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'https://en.wikipedia.org/wiki/Cat',\n",
       " 'title': 'Cat - Wikipedia',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Cat\")\n",
    "wiki = loader.load()\n",
    "wiki[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084566e",
   "metadata": {},
   "source": [
    "Chunking text into manageable segments is crucial to improve the efficiency of search results. Source:https://medium.com/@ayoubkirouane3/simple-chunking-strategies-for-rag-applications-part-1-d56903b167c5\n",
    "\n",
    "The main factors are:\n",
    "- Chunk Size: The size of each chunk should strike a balance between maintaining enough context for meaningful analysis and avoiding excessively large chunks that could affect focus. Smaller chunks (e.g., 256 to 512 tokens) are suited for detailed, granular tasks, whereas larger chunks may be better for understanding broader themes.\n",
    "- Chunk Overlap: An overlap of 100–200 tokens is generally effective. This overlap helps maintain continuity and context between chunks, ensuring that segmentation does not disrupt the flow and coherence of the text.\n",
    "- Task Specificity: The nature of your task significantly impacts the optimal chunking strategy. For tasks involving precise information retrieval, smaller, more focused chunks can enhance retrieval accuracy. Conversely, tasks requiring complex reasoning or broader context might benefit from larger chunks that capture more comprehensive information.\n",
    "- Chunking Strategy: The right chunking strategy depends on your application’s requirements and constraints. For simple, structured content, character splitting or recursive chunking may suffice. For more complex documents, document-specific (like reports or manuals) or semantic chunking might be necessary to preserve context and meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6951c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_documents(text_file)\n",
    "wiki_chunks = text_splitter.split_documents(wiki)\n",
    "documents = text_chunks + wiki_chunks\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdccb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8524\\1794609246.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_function = OllamaEmbeddings(model=\"deepseek-r1:1.5b\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama embeddings using DeepSeek-R1\n",
    "embedding_function = OllamaEmbeddings(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# Parallelize embedding generation\n",
    "def generate_embedding(chunk):\n",
    "    return embedding_function.embed_query(chunk.page_content)\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    embeddings = list(executor.map(generate_embedding, documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2357ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma client and create/reset the collection\n",
    "client = Client(Settings())\n",
    "collection = client.get_or_create_collection(name=\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f301e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents and embeddings to Chroma\n",
    "for idx, chunk in enumerate(documents):\n",
    "    collection.add(\n",
    "        documents=[chunk.page_content], \n",
    "        metadatas=[{'id': idx}], \n",
    "        embeddings=[embeddings[idx]], \n",
    "        ids=[str(idx)]  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14330482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8524\\759129607.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  retriever = Chroma(collection_name=\"cats\", client=client, embedding_function=embedding_function).as_retriever()\n"
     ]
    }
   ],
   "source": [
    "# Initialize retriever using Ollama embeddings for queries\n",
    "retriever = Chroma(collection_name=\"cats\", client=client, embedding_function=embedding_function).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d5c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question):\n",
    "    # Retrieve relevant documents\n",
    "    results = retriever.invoke(question)\n",
    "    # Combine the retrieved content\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90167568",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = retrieve_context('What are the different forms of cat communication?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151ab4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats, at first by staring, hissing, and growling, and, if that does not work, by short and violent, noisy attacks. Although cats do not have a social survival strategy or herd behavior, they always hunt alone.[102]\n",
      "\n",
      "Most cats have five claws on their front paws and four on their rear paws. The dewclaw is proximal to the other claws. More proximally is a protrusion which appears to be a sixth \"finger\". This special feature of the front paws on the inside of the wrists has no function in normal walking but is thought to be an antiskidding device used while jumping. Some cat breeds are prone to having extra digits (\"polydactyly\").[59]\n",
      "\n",
      "Several males, called tomcats, are attracted to a female in heat. They fight over her, and the victor wins the right to mate. At first, the female rejects the male, but eventually, the female allows the male to mate. The female utters a loud yowl as the male pulls out of her because a male cat's penis has a band of about 120–150 backward-pointing penile spines, which are about 1 mm (0.04 in) long; upon withdrawal of the penis, the spines may provide the female with increased sexual stimulation, which acts to induce ovulation.[166]\n",
      "\n",
      "Hunting and feeding\n",
      "See also: Cat food\n",
      "A deermouse is the prey of this domestic cat.\n",
      "The shape and structure of cats' cheeks is insufficient to allow them to take in liquids using suction. Lapping at a rate of four times a second, the cat touches the smooth tip of its tongue to the surface of the water, and quickly retracts it like a corkscrew, drawing water upward into their mouths.[138][139]\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fbbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_deepseek(question, context):\n",
    "    # Format the input prompt\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    # Query DeepSeek-R1 using Ollama\n",
    "    response = ollama.chat(\n",
    "        model=\"deepseek-r1:1.5b\",\n",
    "        messages=[{'role': 'user', 'content': formatted_prompt}]\n",
    "    )\n",
    "    # Clean and return the response\n",
    "    response_content = response['message']['content']\n",
    "    final_answer = re.sub(r'<think>.*?</think>', '', response_content, flags=re.DOTALL).strip()\n",
    "    return final_answer\n",
    "\n",
    "def ask_question(question):\n",
    "    # Retrieve context and generate an answer using RAG\n",
    "    context = retrieve_context(question)\n",
    "    answer = query_deepseek(question, context)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed5e05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The different forms of cat communication include:\n",
      "\n",
      "1. **Staring**: A natural response often used to approach or keep others safe.\n",
      "2. **Hanging down (Hiss)**: A low, resonant sound that can be heard and is used for various reasons.\n",
      "3. **Growling**: A loud, resonant cry that conveys fear or excitement.\n",
      "4. **Dewclaw**: A sixth finger on the front paws that allows easier grip and manipulation of objects.\n",
      "5. **Yowl (from Males)**: A loud sound often associated with anger or dominance.\n",
      "6. **Clatter**: The crunching sound from the back of the cat's legs when something breaks.\n",
      "7. **Tail Thrash**: Rasing the tail, often used to relieve tension and calm others.\n",
      "8. **Bright Light during Social Behavior (Males)**: Cats emit a bright yellow/orange light during active social interactions.\n",
      "9. **Tail Bob**: A bobbing motion of the tail used to alleviate stress or relieve tension.\n",
      "\n",
      "These vocalizations can vary depending on the breed, as some may exhibit more complex communication patterns.\n"
     ]
    }
   ],
   "source": [
    "answer = ask_question('What are the different forms of cat communication?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b95aee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\rag\\deepseek_chatbot\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the Gradio interface\n",
    "import gradio as gr\n",
    "interface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"RAG Chatbot: Cat\",\n",
    "    description=\"Ask any question about Cat. Powered by DeepSeek-R1.\"\n",
    ")\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcdd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c460546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408e5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
